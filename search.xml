<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[布隆过滤器介绍和应用]]></title>
    <url>%2F2018%2F03%2F29%2F%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在日常生活中，包括在设计计算机软件时，我们经常要判断一个元素是否在一个集合中。比如在字处理软件中，需要检查一个英语单词是否拼写正确（也就是要判断 它是否在已知的字典中）；在 FBI，一个嫌疑人的名字是否已经在嫌疑名单上；在网络爬虫里，一个网址是否被访问过等等。最直接的方法就是将集合中全部的元素存在计算机中，遇到一个新元素时，将它和集合中的元素直接比较即可。一般来讲，计算机中的集合是用哈希表（hash table）来存储的。它的好处是快速准确，缺点是费存储空间（因为要同时存储key和value，加上需要解决哈希碰撞，所以实际空间效率&lt;50%）。当集合比较小时，这个问题不显著，但是当集合巨大时，哈希表存储效率低的问题就显现出来了。比如说，一个象 Yahoo,Hotmail 和 Gmai 那样的公众电子邮件（email）提供商，总是需要过滤来自发送垃圾邮件的人（spamer）的垃圾邮件。一个办法就是记录下那些发垃圾邮件的 email 地址。由于那些发送者不停地在注册新的地址，全世界少说也有几十亿个发垃圾邮件的地址，将他们都存起来则需要大量的网络服务器。如果用哈希表，每存储一亿 个 email 地址， 就需要 1.6GB 的内存（用哈希表实现的具体办法是将每一个 email 地址对应成一个八字节的信息指纹（详见：数学之美之信息指纹）， 然后将这些信息指纹存入哈希表，由于哈希表的存储效率一般只有 50%，因此一个 email 地址需要占用十六个字节。一亿个地址大约要 1.6GB， 即十六亿字节的内存）。因此存贮几十亿个邮件地址可能需要上百 GB 的内存。除非是超级计算机，一般服务器是无法存储的。今天我们就介绍一个一种称作布隆过滤器的数学工具，它只需要哈希表 1/8 到 1/4 的大小就能解决同样的问题。布隆过滤器介绍原理如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。链表、树、散列表（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢。Bloom Filter 是一种空间效率很高的随机数据结构，Bloom filter 可以看做是对 bit-map 的扩展, 它的基本原理是：当一个元素被加入集合时，通过 K 个 Hash 函数将这个元素映射成一个位阵列（Bit array）中的 K 个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个 0，则被检索元素一定不在；如果都是 1，则被检索元素很可能在（存在误判率，下文会详解）。如上图可知布隆过滤器的重点有两个：一个bit数组，用来存放映射信息多个Hash函数，用来将元素映射到bit数组布隆过滤器背后的数学原理在于两个完全随机的数学冲突峰概率很小，因此，可以在很小的无识别率的条件下，用很小的空间存储大量的信息。优点相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数。另外, Hash 函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。布隆过滤器可以表示全集，其它任何数据结构都不能。缺点但是布隆过滤器的缺点和优点一样明显。误算率（False Positive）是其中之一。随着存入的元素数量增加，误算率随之增加(误判补救方法是：再建立一个小的白名单，存储那些可能被误判的信息。)。但是如果元素数量太少，则使用散列表足矣。另外，一般情况下不能从布隆过滤器中删除元素. 我们很容易想到把位列阵变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全的删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面. 这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。布隆过滤器的应用场景布隆过滤器决不会漏掉任何一个在黑名单中的可疑地址。但是，它有一条不足之处。比如，它有极小的可能将一个不在黑名单中的电子邮件地址判定为在黑名单中，因为有可能某个好的邮件地址正巧对应个八个都被设置成一的二进制位。好在这种可能性很小。我们把它称为误识概率。不能接受误报的场景以注册用户的例子为例，我们利用布隆过滤器建立以注册的用户名单，判断用户是否可注册，会按照以下步骤执行:传入注册用户的通行证，根据我们建立的已注册用户的布隆过滤器，查询该用户是否存在布隆过滤器中。假设该用户不存在布隆过滤器的集合，对于元素不在集合的结果，布隆过滤器是不会误报，所以可以放心返回该用户可以成功注册的结果。假设用户存在于布隆过滤器，对于元素在集合的结果，布隆过滤器有可能误报，所以我们还需要再查询下真正的数据库，确认用户是否真的已注册了。可以接受误报的场景对于垃圾邮件的黑名单过滤，它有极小的可能将一个不在黑名单中的电子邮件地址判定为在黑名单中。常见的补救办法是在建立一个小的白名单，存储那些可能别误判的邮件地址。应用场景举例chrome、360危险网站识别垃圾邮箱识别爬虫URL去重解决缓存穿透问题……布隆过滤器在java中的使用接下来我将演示如何使用guava中封装的布隆过滤器算法以及说明其误判率。创建代码工程新建一个maven工程，然后在pom中引入guava的依赖：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;19.0&lt;/version&gt; //版本在18以上才提供了布隆过滤器算法 &lt;/dependency&gt;&lt;/dependencies&gt;新建一个测试类BoolmFilterTest,编写如下代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class BoolmFilterTest &#123; private static final int insertions = 1000000;//100w public static void main(String[] args) &#123; //初始化一个存储String数据的布隆过滤器，初始化大小为100w BloomFilter&lt;String&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), insertions,0.01); //初始化一个存储String数据的set，初始化大小为100w，做验证参考 Set&lt;String&gt; sets = new HashSet&lt;String&gt;(insertions); //初始化一个存储String数据额list，初始化大小为100w List&lt;String&gt; lists = new ArrayList&lt;String&gt;(insertions); //向三个容器中初始化100w个随机唯一的字符串 for (int i = 0; i &lt; insertions; i++) &#123; String uuid = UUID.randomUUID().toString(); bloomFilter.put(uuid); sets.add(uuid); lists.add(uuid); &#125; //布隆过滤器误判的次数 int wrongCount = 0; //布隆过滤器正确地次数 int rightCount = 0; //随机抽取1w数据做验证 for (int i = 0; i &lt; 10000; i++) &#123; String test = i % 100 == 0 ? lists.get(i / 100) : UUID.randomUUID().toString(); //布隆过滤器验证通过 if (bloomFilter.mightContain(test)) &#123; if (sets.contains(test)) rightCount++; else wrongCount++; &#125; &#125; System.out.println("right count : " + rightCount); System.out.println("wrong count : "+wrongCount); System.out.println("wrong rate : "+Math.round(((wrongCount*1.0)/(9900))*100)+"%"); &#125;其中insertions表示我们全量数据的大小（但实际bit数组的长度和hash算法的个数都是不定的，根据误判率动态调整）。12BloomFilter&lt;String&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), insertions,0.01);这一行代码建立一个布隆过滤器，工厂方法有三个参数，分别表示过滤器的类型，容量大小，误判率（没错，你可以指定误判率，但是千万别写0，默认是0.03）。接下来我们以100万随机字符串为数据源介绍布隆过滤器的使用以及统计其误判率。由结果可以看到布隆过滤器说不过的确实不过，但是它说过的不一定真的是对的，这就是误判的情况，总体上实际误判率与我们期望的是一致的。我们再来看看算法内部调整的数组长度和hash函数的个数：可以看到为了达到我们要求的误判率，算法包实际创建的bit数组的长度是 9585058，Hash函数的个数是7个，具体为什么是这些数字，可以查看这篇论文了解：http://en.wikipedia.org/wiki/Bloom_filter#Probability_of_false_positives总结我们首先介绍了布隆过滤器的基本原理、优势劣势、使用场景；然后利用guava提供的算法包展示了字符串的判断和测试，并验证了它的误判率。布隆过滤器在行业应用比较广泛，感谢google的工程师为我们提供了好用的算法包。参考https://www.cnblogs.com/haippy/archive/2012/07/13/2590351.htmlhttps://segmentfault.com/a/1190000002729689]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>布隆过滤器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java9初探]]></title>
    <url>%2F2018%2F03%2F09%2Fjava9%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[java自1995年诞生到现在已经23岁了，在这么长的时间里，java的每个版本都会带来快一些新的特性，同时还要保持对旧版本的兼容性，因此java的运行时也变得非常臃肿和庞大，运行时依赖的rt.jar单个文件就有60多M，即使你只是想运行一个简单地helloword,你也不得不加载高达60M+的依赖包。随着微服务和自动化运维的兴起，人们讲究的是快速、精细部署，老态龙钟的java却总是差强人意。可以说java9的出现更多的是为了改善这些问题，提升java的竞争力。个人认为java9最大的改善在以下几个方面：模块化，避免泛滥的代码依赖和说不清道不明的误用。Jlink打包，可以生成一个最小依赖的Image，减少包的大小，轻量部署。提供了类似JShell的新的工具和新的编程API。本篇文章主要目的是对java9的新特性做一个初探。安装java9的安装包可以从这里下载。安装步骤与之前的版本没有什么差别，记得设置java的环境变量哦。安装完成后控制台输入java -version 如果有显示java的版本为9，那说明已经安装成功。文件结构变化我们先看看java9的目录结构：可以看到相比java8多了一些目录,其中最重要的是jmods这个文件夹，里面包含了java9内置的系统模块，而且采用了新的文件格式-jomd。这些文件有什么用呢？其实可以看做是rt.jar的替代，java9的lib里面不再有rt.jar这个巨无霸，而是提供更细粒度的一个个的模块，想用哪个就引用哪个，在使用jlink打包优化的时候会把没有用到的依赖都去掉，仅仅保留一个最小依赖的运行包，是不是很适合微服务和容器部署？我们可以在控制台输入命令java --list-modues来查看所有系统提供的基础模块，应该是94个模块。Jshell我们都知道Ruby,Scala,Groovy,Clojure都有提供一个REPL工具，这个工具可以让使用者快速的了解语言的特性，现在java9也有了这样的工具-Jshell。java9安装成功后，打开控制台输入jshell便可开启这个工具，我们可以简单地测试一下更多详细的用法可以参考这里。模块化java9最大的改变应该就是模块化了，回想我们以前的版本，把一个jar放到classpath中，那么实际所有的第三方都可以访问里面的public的类和方法，即使某个类、某个方法是不想被外界使用的，你毫无办法去控制你的公开的类不被别人访问，还记得Oracle为了不让开发者使用”sun“这个包所做的人工声明么？现在java9来了，这已经不是一个问题，模块可的可用性具体体现在两个方面：可读的、可访问的。如果一个模块在我的modulePath（注意，不是classPath）中，那么这个模块对我来说是可读的；但是我能访问这个模块里面的哪些类呢，那是模块的开发者决定的。每个模块都有一个模块描述文件module-info.java（没错这不是一个合法的类名称，他们故意这样的），类似nodejs的package.json,文件里面定义了我要requires哪些模块，我exports哪些模块给别人用。我没有exports的类你即使添加了对该模块的依赖依然是无法访问的。1234567module packt.addressbook &#123;requires packt.sortutil;&#125;module packt.sortutil &#123;exports packt.util;&#125;我会在后续详细讲解模块的使用。JlinkJava 应用可以通过新增的 jlink 工具，创建出只包含所依赖的JDK模块的自定义运行时镜像。这样可以极大的减少 Java 运行时环境的大小。使得JDK可以在更小的设备中使用。采用模块化系统的应用程序只需要这些应用程序所需的那部分JDK模块，而非是整个JDK框架了。HTTP/2JDK9之前提供HttpURLConnection API来实现Http访问功能，但是这个类基本很少使用，一般都会选择Apache的Http Client，此次在Java 9的版本中引入了一个新的package:java.net.http，里面提供了对Http访问很好的支持，不仅支持Http1.1而且还支持HTTP2，以及WebSocket，据说性能特别好。不可变集合工厂方法Java 9增加了List.of()、Set.of()、Map.of()和Map.ofEntries()等工厂方法来创建不可变集合。12345List strs = List.of("Hello", "World");List strs List.of(1, 2, 3);Set strs = Set.of("Hello", "World");Set ints = Set.of(1, 2, 3);Map maps = Map.of("Hello", 1, "World", 2);除了更短和更好阅读之外，这些方法也可以避免您选择特定的集合实现。在创建后，继续添加元素到这些集合会导致 “UnsupportedOperationException” 。私有接口方法Java8为我们提供了接口的默认方法和静态方法，接口也可以包含行为，而不仅仅是方法定义。默认方法和静态方法可以共享接口中的私有方法，因此避免了代码冗余，这也使代码更加清晰。如果私有方法是静态的，那这个方法就属于这个接口的。并且没有静态的私有方法只能被在接口中的实例调用。12345678910111213141516171819interface InterfaceWithPrivateMethods &#123; private static String staticPrivate() &#123; return "static private"; &#125; private String instancePrivate() &#123; return "instance private"; &#125; default void check() &#123; String result = staticPrivate(); InterfaceWithPrivateMethods pvt = new InterfaceWithPrivateMethods() &#123; // anonymous class 匿名类 &#125;; result = pvt.instancePrivate(); &#125;&#125;多版本兼容当一个新版本的 Java 出现的时候，你的库用户要花费很长时间才会切换到这个新的版本。这就意味着库要去向后兼容你想要支持的最老的 Java 版本 (许多情况下就是 Java 6 或者 7)。这实际上意味着未来的很长一段时间，你都不能在库中运用 Java 9 所提供的新特性。幸运的是，多版本兼容 JAR 功能能让你创建仅在特定版本的 Java 环境中运行库程序时选择使用的 class 版本：在上述场景中， multirelease.jar 可以在 Java 9 中使用, 不过 Helper 这个类使用的不是顶层的 multirelease.Helper 这个 class, 而是处在“META-INF/versions/9”下面的这个。这是特别为 Java 9 准备的 class 版本，可以运用 Java 9 所提供的特性和库。同时，在早期的 Java 诸版本中使用这个 JAR 也是能运行的，因为较老版本的 Java 只会看到顶层的这个 Helper 类。其他HTML5风格的Java帮助文档、统一JVM日志、I/O流新特性等。传送门]]></content>
      <categories>
        <category>java9</category>
      </categories>
      <tags>
        <tag>java9初探</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发Linux参数优化]]></title>
    <url>%2F2018%2F02%2F27%2F%E9%AB%98%E5%B9%B6%E5%8F%91Linux%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[因为默认的Linux的内核参数考虑的是一般通用的场景，这明显不符合用于支持高并发访问的场景，所以我们需要修改Linux的内核参数，让服务器可以支持更多的连接和并发。我们这里的地是修改Linux内核参数使得Nginx可以支持更多的并发请求。sysctl.conf是一个允许您改变正在运行中的Linux系统的接口。它包含一些 TCP/IP 堆栈和虚拟内存系统的高级选项， 这可以让有经验的管理员提高引人注目的系统性能，首先，使用vim编辑器打开/etc/sysctl.conf 文件，默认情况下文件里面是没有配置内容的，我们添加内容如下：12345678910111213141516fs.file-max = 999999net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.ip_local_port_range =1024 61000net.ipv4.tcp_rmem =4096 32768 262142net.ipv4.tcp_wmem =4096 32768 262142net.core.netdev_max_backlog = 8096net.core.rmem_default = 262144net.core.wmem_default = 262144net.core.rmem_max = 2097152net.core.rmem_max = 2097152net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024上面参数意义解释如下：file-max: 这个参数表示进程可以同时打开的最大文件句柄数，这个参数直接限制最大并发连接数，需要根据实际情况配置。tcp_tw_reuse: 这个参数设置为1，表示允许将TIME—WAIT状态的socket重新用于新的TCP连接，这对服务器来说很有意义，因为服务器上总是会有大量的TIME-WAIT状态的连接。tcp_keepalive_time: 这个参数表示当keepalive启用时，TCP发送keealive消息的频度。默认是2小时，如果将其设置小一些，可以更快地清理无效的连接。tcp_fin_timeout: 这个参数表示当服务器主动关闭连接的时候，socket保持在FIN-WAIT-2状态的最大时间。tcp_max_tw_buckets: 这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数量，套接字将立即被清除并打印警告信息。该参数默认为180000，过多的TIME_WAIT套接字会使得Web服务器变慢。tcp_max_syn_backlog: 这个表示TCP三次握手建立阶段服务器接收SYN请求队列的最大长度，默认是1024。将其设置大一些可以使得Nginx繁忙来不及accept新连接的时候不至于丢失客户端发起的连接请求。ip_local_port_range: 这个参数定了在UDP和TCP连接本地端口的取值范围。tcp_rmem: 这个参数定义了TCP接收缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值tcp_wmen: 这个参数定义了TCP发送缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值netdev_max_backlog: 当网卡接收数据包的速度大于内核处理数据的时候，会有一个队列保存这些数据包。这个参数表示这个队列的最大值。rmem_default：这个参数表示内核套接字接收缓存区默认的大小。wmem_default：这个参数表示内核套接字发送缓存区默认的大小。rmem_max：这个参数表示内核套接字接收缓存区默认的最大大小。wmem_max：这个参数表示内核套接字发送缓存区默认的最大大小。tcp_syncookies: 这是一个开关，是否打开SYN Cookie功能，该功能可以防止部分SYN攻击。tcp_max_syn_backlog: 端口最大 backlog 内核限制。此参数限制 服务端应用程序 可以设置的端口最大 backlog 值 (对应于端口的 syn_backlog 和 backlog 队列长度)。动机是在内存有限的服务器上限制/避免应用程序配置超大 backlog 值而耗尽内核内存。如果应用程序设置 backlog 大于此值，操作系统将自动将之限制到此值。修改完成后执行如下命令让参数立即生效：12/sbin/sysctl -p]]></content>
      <categories>
        <category>高性能服务</category>
      </categories>
      <tags>
        <tag>Linux参数优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lanlan]]></title>
    <url>%2F2018%2F02%2F27%2Flanlan%2F</url>
    <content type="text"><![CDATA[因为默认的Linux的内核参数考虑的是一般通用的场景，这明显不符合用于支持高并发访问的场景，所以我们需要修改Linux的内核参数，让服务器可以支持更多的连接和并发。]]></content>
      <categories>
        <category>程序生活</category>
      </categories>
      <tags>
        <tag>减肥</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扩展hexo-qiniu-sync插件支持自动资源文件]]></title>
    <url>%2F2018%2F01%2F14%2Fhexo-qiniu2%2F</url>
    <content type="text"><![CDATA[前面在搭建个人博客的时候使用了hexo-qiniu-sync来对接七牛存储，自动完成图片、css和js的上传以及标签解析。但是我们写技术博客的时候经常会附加一些代码文件或者压缩包之类的，我就想能否扩展一下这个插件也让它能够自动帮我们完成上传和标签解析。所以，我fork原作者的代码，并修改了源代码，放在这里，对原作者表示感谢。我同时把修改后的插件上传到了npm，只要通过一下命令安装即可：1npm install hexo-qiniu-sync2 --save用法：其他用法参考源插件，资源文件使用的地方插入1&#123;% qnAsset test.txt title:'测试资源文件' alt:'测试文件' %&#125;生成的html代码：1&lt;a title="测试资源文件" alt="测试文件" href="http://p24hn6n30.bkt.clouddn.com/static/asset/test.txt" target="_blank" rel="noopener"&gt;测试资源文件&lt;/a&gt;]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Mybatis实现事务内多数据源切换2]]></title>
    <url>%2F2018%2F01%2F13%2FSpringMybatisMutilDataSource2%2F</url>
    <content type="text"><![CDATA[上一篇我介绍了如何在SpringBoot+Mybatis中实现多数据源的动态切换。这一篇我将介绍为什么自动切换在事务笼罩下的Service方法内会失效，并说明其解决办法，好，让我们开始。问题缘由首先让我们先配置一个事物管理器以及它的AOP拦截切面：12345678910111213141516171819202122232425262728293031&lt;tx:advice id="txAdvice" transaction-manager="transactionManager" &gt; &lt;tx:attributes&gt; &lt;tx:method name="insert*" propagation="REQUIRED" rollback-for="Exception" /&gt; &lt;tx:method name="create*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="add*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="update*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="modify*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="edit*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="delete*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="remove*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="save*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="send*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="get*" read-only="true"/&gt; &lt;tx:method name="find*" read-only="true"/&gt; &lt;tx:method name="query*" read-only="true"/&gt; &lt;tx:method name="search*" read-only="true"/&gt; &lt;tx:method name="select*" read-only="true"/&gt; &lt;tx:method name="count*" read-only="true"/&gt; &lt;tx:method name="list*" read-only="true"/&gt; &lt;tx:method name="load*" read-only="true"/&gt; &lt;!--&lt;tx:method name="*" propagation="REQUIRED" isolation="REPEATABLE_READ"/&gt;--&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!--配置拦截所有xxxService中的public方法--&gt;&lt;aop:config expose-proxy="true" proxy-target-class="true" &gt; &lt;aop:pointcut expression="execution(public * com.smartdata360..service.*Service.*(..))" id="pt"/&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="pt" order="2"/&gt;&lt;/aop:config&gt;当我们配置了事物管理器和拦截Service中的方法后，每次执行Service中方法前会开启一个事务，并且同时会缓存一些东西：DataSource、SqlSessionFactory、Connection等所以，我们在外面再怎么设置要求切换数据源也没用，因为Conneciton都是从缓存中拿的，所以我们要想能够顺利的切换数据源，实际就是能够动态的根据DatabaseType获取不同的Connection，并且要求不能影响整个事物的特性。解决问题我们既想实现动态的获取不同的Connection对象，又不想破坏事务的特性，那怎么办？我想到的办法就是重写事物管理器。SpringBoot中默认用到的是SpringManagedTransactionFactory这个工厂类来创建事务对象SpringManagedTransaction而事务对象有我要的方法所以我决定改写这两个类，首先是重写一个Transaction类的实现，它封装了怎么获取Connection对象。dataSource保持了当前的数据源对象，实际就是DynamicDataSourcemainConnecition表示当前事务对应的ConnectionmainDatabaseIdentification表示当前事务对应的数据源标识otherConnectionMap表示Service中用到的其他的数据源Connection对象首先看我们如何获取一个Conneciton对象：12345678910111213141516171819202122232425262728293031323334353637383940414243 @Override public Connection getConnection() throws SQLException &#123; DatabaseType databaseType = DatabaseContextHolder.getDatabaseType();// notNull(databaseType, "DatabaseType can not be null"); if (databaseType == null) databaseType = DatabaseType.getDefault(); String databaseIdentification = databaseType.getValue(); if (databaseIdentification.equals(mainDatabaseIdentification)) &#123; if (mainConnection != null) return mainConnection; else &#123; openMainConnection(); mainDatabaseIdentification =databaseIdentification; return mainConnection; &#125; &#125; else &#123; //获取其他的数据源连接 if (!otherConnectionMap.containsKey(databaseIdentification)) &#123; try &#123; Connection conn = dataSource.getConnection(); otherConnectionMap.put(databaseIdentification, conn); &#125; catch (SQLException ex) &#123; throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex); &#125; &#125; return otherConnectionMap.get(databaseIdentification); &#125; &#125; private void openMainConnection() throws SQLException &#123; this.mainConnection = DataSourceUtils.getConnection(this.dataSource); this.autoCommit = this.mainConnection.getAutoCommit(); this.isConnectionTransactional = DataSourceUtils.isConnectionTransactional(this.mainConnection, this.dataSource); if (LOGGER.isDebugEnabled()) &#123; LOGGER.debug( "JDBC Connection [" + this.mainConnection + "] will" + (this.isConnectionTransactional ? " " : " not ") + "be managed by Spring"); &#125; &#125;首先从当前线程变量中获取DatabaseType，然后取到当前的数据源标识，如果是mainDatabaseIdentification那么就从事务中获取事务自己管理的Connection；否则使用dataSource获取一个并且缓存起来（这时候会触发determineCurrentLookupKey方法的执行），避免重复获取。这样我们在外面设置的DatabaseType已经渗透到事物管理器内部了，也实现了Connection对象的动态获取。但是我们不能改变事务处理的特性，所以其他的副Connection的状态应该与mainConnection保持一致，同样我改写了其他几个方法：这样所有的Connection的状态与当前事务是一致的了。之前想过atomikos来实现分布式事务；我不确定我这种方法能否做到同一个事务在多个数据库上的一致性和隔离性。好，核心的东西介绍完成了，那么我们怎么和Mybaits结合呢？很简单，我们也实现一个工厂类创建我们自己的事务处理对象：123456789101112131415161718/** * 支持Service内多数据源切换的Factory * Created by yuananyun on 2017/7/19. */public class MultiDataSouceTransactionFactory extends SpringManagedTransactionFactory &#123; /** * &#123;@inheritDoc&#125; * * @param dataSource * @param level * @param autoCommit */ @Override public Transaction newTransaction(DataSource dataSource, TransactionIsolationLevel level, boolean autoCommit) &#123; return new MultiDataSourceTransaction(dataSource); &#125;&#125;然后把这个工厂类挂到Mybatis的配置方法里面去：如此，大功告成，附带MultiDataSourceTransaction类的源码MultiDataSourceTransaction]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>SpringBoot,Mybatis,多数据源切换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Mybatis实现事务内多数据源切换1]]></title>
    <url>%2F2018%2F01%2F13%2FSpringMybatisMutilDatasource%2F</url>
    <content type="text"><![CDATA[背景目前SpringBoot+Mybatis使用人的还比较多，我们项目有需求在一个项目中使用多个数据源，所以我就借助于Spring提供的AbstractRoutingDataSource类实现了多数据源的切换。一切都很好，直到遇到了事务处理内的数据源切换，因为一个事务处理开始的时候就会把DataSource、Connection给缓存了，所以不管你在外面怎么配置切换，都不能实现connection的切换。经过查看和调试源代码，总算是找到了一条解决的路，现在写出来供需要的朋友做参考。我的计划是写两篇文章来说明这个事情，第一篇主要是介绍如何实现项目中多数据源的切换；第二篇主要是介绍如何解决事务中数据源的动态切换。实现原理我们首先来看看动态数据源动态切换的原理:如上图所示，我们使用一个DynamicDataSource这个数据源来代理多个数据源，让上层感知不到后面的多个数据源，然后我们在线程上下文中根据需要来动态切换使用真正的数据源，那么就可以用常规的方法解决了多数据源的读取了。感谢Spring为我们提供了这么一个代理数据源类：AbstractRoutingDataSource。该类有个方法用于在每次连接数据库的时候获取目标数据源:123456789101112protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, "DataSource router not initialized"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException("Cannot determine target DataSource for lookup key [" + lookupKey + "]"); &#125; return dataSource;&#125;所以我们可以实现determineCurrentLookupKey这个方法来注入我们的数据源选择逻辑，比如我的一个实现:123456@Overrideprotected Object determineCurrentLookupKey() &#123; DatabaseType type = DatabaseContextHolder.getDatabaseType(); if (type == null) type = DatabaseType.getDefault(); return type.getValue();&#125;DatabaseType是一个自定义的Enum对象，只是为了区分不同的数据源而已。DatabaseContextHolder也是一个自定义类，目的是保持每个线程的各自的独立变量，你可能猜到了与ThreadLocal有关。使用的时候在项目中配置多个数据源：我这里配置了两个数据源，对应到第一张图，很明显了吧。好，工具都准备好了，现在看我们怎么用。首先我们肯定是在获取数据源的Connection之前设置好使用的DatabaseType，并且这个变量是与当前线程绑定的；然后DynamicDataSource在获取Conneciton的时候会通过方法determineCurrentLookupKey来获取一个真正的DataSource来开启一个Conneciton；接下来就是交给Mybaitis来完成数据库操作了。那么我们在哪里设置这个DatabaseType呢？每次需要切换前？这肯定没错，但是手工操作也太low了，所以我这里写了一个AOP方法来自动设置这个标识：12345678910111213141516171819202122232425262728293031323334@Aspect@Component@Order(1)public class DataSourceAspect &#123; @Pointcut("execution(* com.smartdata360..mapper.*Mapper.*(..))") public void datasourcePoint() &#123; &#125; @Around("datasourcePoint()") public Object handler(ProceedingJoinPoint point) throws Throwable &#123; Signature signature = point.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method method = methodSignature.getMethod(); MultiDataSource multiDataSource = method.getAnnotation(MultiDataSource.class); if (multiDataSource == null) &#123; Class&lt;?&gt; clazz = method.getDeclaringClass(); multiDataSource = clazz.getAnnotation(MultiDataSource.class); &#125; DatabaseType databaseType = DatabaseType.getDefault(); if (multiDataSource != null) databaseType = multiDataSource.value(); try &#123; DatabaseContextHolder.setDatabaseType(databaseType); Object result = point.proceed(); DatabaseContextHolder.clearDatabaseType(); return result; &#125; finally &#123; DatabaseContextHolder.clearDatabaseType(); &#125; &#125;&#125;首先，我指定我拦截所有Mapper类的所有方法，也就是我们的数据源切换是Mapper级别的；然后我从类或方法签名上查找MultiDataSource这个标注，如果有，那么直接取出设置的值，如果没有，那么直接设置primary为默认数据源；最后一步就是执行完后要清理一下这个标识，免得给下一次执行造成影响。这样我们就可以用给类或方法打标注的方式来决定我们使用哪个数据源了，如果没指定那么直接默认用primary数据源：123456789101112131415@MultiDataSource(DatabaseType.second)public interface NativeMapper&lt;String&gt; &#123; @Select("select address from dim_card_native where id=#&#123;idcard&#125; limit 1") public String selectOne(@Param("idcard") String idcard); /** *插入缺失的身份证籍贯 * @param idCard */ @Insert("insert into dim_card_native(id,address) select #&#123;idcard&#125;,' ' " + " where not exists(select id from dim_card_native where id=#&#123;idcard&#125;)") void insetBlankCard(@Param("idcard") String idCard);&#125;一切就是这么简单得实现了多数据源的自动切换，但是当我们在Service上开启事务的时候就会出问题了：切换数据源失效！原因和如何解决请看下一篇的讲解。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>SpringBoot,Mybatis,多数据源切换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo集成hexo-qiniu-sync插件]]></title>
    <url>%2F2018%2F01%2F06%2Fhexo-qiniu%2F</url>
    <content type="text"><![CDATA[背景今天抽空在博客中集成hexo-qiniu-sync插件，主要目的是想把博客中用到的资源，比如图片、文件等放到七牛云存储，这样博客中只要通过url引用资源就行了，不仅方便而且安全。hexo-qiniu-sync是一个hexo插件， 可以让你在文档中入嵌存储在七牛上的图片、JS、CSS类型的静态文件。你可以不用手动上传文件到七牛，插件会自动帮你将本地目录的文件同步到七牛。项目地址环境要求：已经安装好了nodejs和npm已经初始化一个hexo博客目录已经安装了git，并且关联到了github所有的以上要求可以参考这里来完成。在hexo初始化后的博客根目录执行如下语句来安装插件：npm install hexo-qiniu-sync –save开通七牛存储可以点击这里来注册七牛存储，免费个人有10G的存储空间，个人博客应该足够使用了。注册成功后，进入”资源主页”添加一个”对象存储”来存放我们的博客资源。存储空间名称写”yayblog”,选择华南地区、公开空间创建一个对象存储。点击刚创建的存储空间查看空间信息：其中”内容管理”可以管理存储空间中的内容；”图片样式”可以为上传的图片做一些处理，比如剪裁、压缩、加水印等；七牛还给了一个测试域名，你也可以绑定自己的域名，但是需要中国特色的 “备案”，我使用的国外的域名，所以这里用得是这个测试域名。在”个人中心”可以查看刚自己的AccessKey/SecretKey，这个是七牛颁发的凭证，稍后配置的时候会使用。至此，七牛存储已经准备就绪，我们重新回到我们的博客目录。配置插件打开根目录的_config.yml,添加如下配置：12345678910111213141516171819202122232425262728293031323334353637#plugins:#- hexo-qiniu-sync#七牛云存储设置##offline 是否离线. 离线状态将使用本地地址渲染##sync 是否同步##bucket 空间名称.##access_key 上传密钥AccessKey##secret_key 上传密钥SecretKey##secret_file 秘钥文件路径，可以将上述两个属性配置到文件内，防止泄露，json格式。绝对路径相对路径均可##dirPrefix 上传的资源子目录前缀.如设置，需与urlPrefix同步##urlPrefix 外链前缀.##up_host 上传服务器路径,如选择华北区域的话配置为http://up-z1.qiniu.com##local_dir 本地目录.##update_exist 是否更新已经上传过的文件(仅文件大小不同或在上次上传后进行更新的才会重新上传)##image/js/css 子参数folder为不同静态资源种类的目录名称，一般不需要改动##image.extend 这是个特殊参数，用于生成缩略图或加水印等操作。具体请参考http://developer.qiniu.com/docs/v6/api/reference/fop/image/## 可使用基本图片处理、高级图片处理、图片水印处理这3个接口。例如 ?imageView2/2/w/500 即生成宽度最多500px的缩略图qiniu: offline: false sync: true bucket: yayblog secret_file: null access_key: 七牛给的密钥 secret_key: 七牛给的密钥 dirPrefix: static urlPrefix: http://前面七牛给的测试域名/static up_host: http://upload.qiniu.com local_dir: static update_exist: true image: folder: images extend: js: folder: js css: folder: css这里要注意的是，参考作者的文档，会报错，正常的是不需要在这里写插件注册，也就是注释以下语句：#plugins:#- hexo-qiniu-sync这个插件的原理就是指定一个本地的目录local_dir和七牛对象存储的一个目录做映射，当发现本地目录中文件有变化的时候就自动上传到配置好的七牛的对象存储空间。根据作者的说法，这个本地local_dir是会自动创建的，但是不知道他有没有测试macos系统的情况。经过测试会出现权限不足的情况，所以需要执行命令把整个文件夹授权给当前用户，比如简单粗暴：chmod a+rwx .万一真的不行，我还可以手动创建，但是需要注意新建的static文件夹的位置要和source平级，而不是source里面：通过以上配置后，我们在static/images里面添加一张图片，然后执行命令：hexo qiniu sync就会在七牛网站对应的对象存储内容里面看到上传的图片啦至此，我们已经完成了这个插件的配置，在markdown中使用图片：图片处理还记得我们前面的配置项里面有个image : extend的参数吗，这个是给图片处理预留的，也就是七牛可以自动对上传的图片做处理。可以使用 基本图片处理（imageView2）、高级图片处理（imageMogr2）、图片水印处理（watermark） 这三个图片处理接口，多个接口内容之间用 | 间隔。例如 ?imageView2/2/w/500 即生成宽度最多500px的缩略图。以图片水印为例，我需要在我博客里面的图片上加上站点url的水印。首先我们在七牛的对象存储配置一个图片样式blogImg：完成后，回到博客根目录的配置文件修改配置项：extend: -blogImg这样当我们下载或引用图片的时候会自动加上了设置的水印。这是一个全局的配置，可能我们不是所有的图片都需要水印，这种情况我们可以在七牛创建多个图片样式，然后再引用图片的时候指定extend来指定生效的图片样式，标签中的设置会覆盖全局的设置，如：]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开通个人博客]]></title>
    <url>%2F2018%2F01%2F06%2Ffirst%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;一直断断续续在博客园写了将近七年的博客，期间也换了几次电脑了，所发的博文的原文也都丢了，此外，第三方博客平台终究不是那么自由，个人站点更适合作为个人名片。&nbsp;&nbsp;&nbsp;&nbsp;后来github出现了，有想法把博文建立一个repository，这样不仅可以永久保留原文，而且还可以跟踪不同的版本，方便修改和完善。&nbsp;&nbsp;&nbsp;&nbsp;再后来出现了hexo这个非常good的项目，可以直接把博文编译成静态html，然后很方便的部署到网页服务器（比如github的pages、nginx等）。&nbsp;&nbsp;&nbsp;&nbsp;今天，作为程序员使用最多的编辑器肯定是Eclipse和IDEA之类的代码编辑器，然后我又有了用IDEA写博客的想法。写代码的时候突然有了灵感想写一篇博客，然后直接在IDEA里面new一个文件，拍拍拍，一气呵成，一键更新，快哉！&nbsp;&nbsp;&nbsp;&nbsp;2018年来临了，今年给自己的规划是：多读书，多写博客，早睡早起身体好。所以花了几天搭建了这个博客站点，作为一个新的开始罢。我是一只奋斗中的眼镜兔，请记住我的头像：]]></content>
      <categories>
        <category>人生感悟</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
</search>
